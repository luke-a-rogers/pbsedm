---
title: "Inclusion Issue Version 5 (update rEDM Simplex() again, report version number)"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{inclusion_issue_4}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  fig.width = 5,
  fig.height = 5
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

```{r setup}
library(pbsEDM)
```

## Introduction

This vignette was more for working things out. Now defining Aspects 1, 2 and 3
in the manuscript, so creating aspect_2.Rmd (and maybe aspect_1.Rmd and
aspect_3.Rmd if needed) based on this one. And then can delete this.

<!-- Change what's below based on
edm-work/code/simulated/sockeye-simulated/sockeye-sim-edm.Snw - has the movie
edm-work/code/simulated/egDeyle/egDeyle.rnw (that I used for different tstar,
for EAFMWG Jan 2020 I used egDeyleT95tstar15.rnw - can generalise once get
going here.
edm-work/code/simulated/egDeyle/tstarLoop/tstarLoop2019.rnw
and
edm-work/code/simulated/egDeyle/tstarLoop/mwe-2019.r
-->
```{r fullresults}
as.data.frame(head(NY_lags_example_3))
as.data.frame(tail(NY_lags_example_3))
```
Also included are results from using the `rEDM`
package with embedding dimension 2 (see below) as `rEDM.pred` for the predicted
value of `Y_t` with `rEDM.var`
for its variance, and results from Andy's original
function `EDM_pred_E_2()`, saved as `my.pred` and `my.var`.
See `?NY_lags_example_3` for full details. THE HELP WILL NEED UPDATING.

This is the code to check that `rEDM::Simplex()` gives the stated results, but
it is not run in this vignette to avoid `pbsEDM` being dependent
on `rEDM` (and its dependencies). Can be used to simply check future versions of
both packages.
```{r compareredm, eval=FALSE}
library(rEDM)
packageVersion("rEDM")
# '1.13.0', published 2022-06-17
input <-  dplyr::select(NY_lags_example_3, t, Y_t) %>%
  dplyr::rename(Time = t)

check_rEDM <- rEDM::Simplex(dataFrame = input,
                            columns = "Y_t",
                            target = "Y_t",
                            lib = "1 99",
                            pred = "1 99",
                            E = 2,
                            verbose = TRUE)
check_rEDM_pred <- c(NA,
                     check_rEDM$Predictions)   # Needs extra NA to get indexing correct

check_rEDM_pred_var <- c(NA,
                         check_rEDM$Pred_Variance)

testthat::expect_equal(NY_lags_example_3$rEDM.pred,
                       check_rEDM_pred)       # If no error then they match
testthat::expect_equal(NY_lags_example_3$rEDM.var,
                       check_rEDM_pred_var)   # If no error then they match

```

## Predictions using pbsEDM code

Now use the new `pbsEDM` code that Luke wrote independently; see the
[`analyse_simple_time_series`](analyse_simple_time_series.html) vignette for details on
using it. Then compare `pbsEDM` results with those from `rEDM` and from Andy's manual code:
```{r pbsEDMcalc}
pbs_calc <- pbsEDM(NY_lags_example_3,
                   lags = list(Y_t = c(0:1))) # A tibble (contains lists)

testthat::expect_equal(NY_lags_example_3$Y_t,
                       pbs_calc$X_observed[-length(pbs_calc$X_observed)])
                       # verifying the indexing is the same because X_observed has an extra NA value
                       # to match pbs_calc$X_forecast (to allow for forecasts of unlagged data)

pbs_pred <- pbs_calc$X_forecast[-length(pbs_calc$X_forecast)]

testthat::expect_equal(NY_lags_example_3$my.pred,
                       pbs_pred)
```
That last line will cause an error if the `pbsEDM` results do not match the
`my.pred` values from Andy's manual code (there is no error because they do match).

**Conclusion**: Andy's original manual calculations and Luke's new function in
`pbsEDM` give the same results for this simulated data set. Andy's and Luke's
code was written independently (although Andy had explained why his results
differed to those from `rEDM`). This is a reassuring test of Luke's new code,
which is more general and functionalised than Andy's, and can do more than just $E=2$.
Thus, we will continue using the `pbsEDM` results.

## Redoing inputting the N value, else the output has N for Y which is confusing

Using

$\hat{N_{t+1}} = N_t + \hat{Y_t}$


```{r pbsEDMcalc2}
N_t <- NY_lags_example_3$N_t
Y_t <- NY_lags_example_3$Y_t

pbs_calc2 <- pbsEDM(NY_lags_example_3,
                    lags = list(N_t = c(0:1)),
                    first_difference = TRUE) # A tibble (contains lists)

testthat::expect_equal(N_t,
                       pbs_calc2$N_observed[-length(pbs_calc2$N_observed)])
                       # verifying the indexing is the same because X_observed has an extra NA value
                       # to match pbs_calc$X_forecast (to allow for forecasts of unlagged data)

testthat::expect_equal(NY_lags_example_3$Y_t,
                       pbs_calc2$Y_observed)

pbs_calc2$results
#  E     N_rho  N_rmse    X_rho  X_rmse
#  2 0.2973217 1.12366 0.703475 1.12366
# N_rho is way smaller than X_rho! Check manually:

# Now use Andy's original calculations:
my_pred_Y <- NY_lags_example_3$my.pred

# \hat{N_{t+1}} = N_t + \hat{Y_t}
my_pred_N <- c(NA,
               N_t + my_pred_Y)
# Can't predict N[3] since can't predict Y_2 since can't use t^*=1 as focal point

# Check mine and pbsEDM (commenting out to build vignette, but needs figuring out):
#testthat::expect_equal(my_pred_N,
#                       pbs_calc2$N_forecast)
# What?! How come only one weird one:
#Error: `my_pred_N` not equal to pbs_calc2$N_forecast.
#1/101 mismatches
#[78] -0.202 - 1.21 == -1.41
# See Issue #29 - I'm not sure if rest of pbsEDM function is updated.
# How about:
testthat::expect_equal(NY_lags_example_3$N_t,
                       pbs_calc2$N_observed[-101])
# So definitely using the same N values.


# But these work:
testthat::expect_equal(NY_lags_example_3$my.pred,
                       pbs_pred)

testthat::expect_equal(pbs_calc$X_forecast,
                       pbs_calc$Y_forecast)

testthat::expect_equal(pbs_calc$X_forecast[-101],
                       NY_lags_example_3$my.pred)

# Okay, so just stick with my N calculation
#  since pbs X or Y forecast is same as my.pred, until fix #29.
plot(c(N_t, NA),
     my_pred_N,
     xlab = "Observation of Nt",
     ylab = "Estimate of Nt")
abline(0, 1, col="grey")

plot(Y_t,
     my_pred_Y,
     xlab = "Observation of Yt",
     ylab = "Estimate of Yt")
abline(0, 1, col="grey")

my_rho_N <- cor(c(N_t, NA),
                my_pred_N,
                use = "pairwise.complete.obs")
my_rho_N
pbs_calc2$results
# N_rho slightly different presumably due to that one different value.
```

Doesn't look great. Thought about alternative definition:

$\hat{N_{t+1}} = \hat{N_t} + \hat{Y_t}$

but first $\hat{Y_t}$ is $\hat{Y_3}$ so we have

$\hat{N_4} = \hat{N_3} + \hat{Y_3}$

but we don't know $\hat{N_3}$ (because don't know $\hat{Y_2}$. So this wouldn't
work anyway (and it seems like it would just compound errors anyway).

So that's a super low correlation coefficient, compared to that based on the
$Y_t$. So EDM has given a misleadingly impression of prediction accuracy based
on estimating $Y_t$,
because what we're interested in is predicting $N_t$ not $Y_t$.

Note this is all with setting $E=2$, and the analysis on $Y_t$ suggested
$E=3$. TODO: do the full analysis (other vignette) using $N_t$ to see what value
of $E$ is suggested and what the resulting $\rho$ is. Needs pbsEDM issue 29 fixed.

Okay, trying to debug the problem above, that one (but only one) forecast $N_t$
comes out different between mine and Luke's, but the $Y_t$'s don't (implying
nearest neighbours etc are the same).
```{r debug}
# First check from scratch:
pbs_calc3 <- pbsEDM(NY_lags_example_3,
                    lags = list(N_t = c(0:1)),
                    first_difference = TRUE) # A tibble (contains lists)
pbs_calc3$Y_forecast - my_pred_Y
# So this doesn't hold, it's to do with doing the
#  first_difference within pbsEDM:

# This is done above, using the Y_t values we already have (and so then not first-differencing)
#pbs_calc <- pbsEDM(NY_lags_example_3,
#                   lags = list(Y_t = c(0:1))) # A tibble (contains lists)
testthat::expect_equal(NY_lags_example_3$my.pred,
                       pbs_pred)    # Is fine.

#testthat::expect_equal(pbs_calc$Y_forecast[-101],
#                       pbs_calc3$Y_forecast)
# 1/100 mismatches
# [77] -0.381 - 1.03 == -1.41

# TODO: HERE

# Put a browser into pbsEDM()

```

### How about working in the log scale

Joe suggested trying on the log scale. So use $\log N_t$ values. Then
define $Y'_t$ as

$Y'_t = \log N_{t+1} - \log N_t = \log \dfrac{N_{t+1}}{N_t}$

and the reverse transformation becomes

$\hat{N}_{t+1} = N_t \textrm{e}^{\hat{Y'}_t}$

```{r logcalcs}
Nt_log <- dplyr::mutate(NY_lags_example_3,
                        "logN_t" = log(N_t)) %>%
  dplyr::select(logN_t)
pbs_log <- pbsEDM(Nt_log,
                  lags = list(logN_t = c(0:1)),
                  first_difference = TRUE)

pbs_log$results
# Work out explicitly here given above issue with one value being different to
#  my calcs:
pbs_logN_fore <- c(NA,
                   Nt_log$logN_t + pbs_log$X_forecast)
pbs_rho_logN_manual <- cor(c(Nt_log$logN_t, NA),
                           pbs_logN_fore,
                           use = "pairwise.complete.obs")
testthat::expect_equal(pbs_rho_logN_manual,
                       pbs_log$results$N_rho)
# Now un-log:
pbs_N_fore <- exp(pbs_logN_fore)
pbs_rho_N_manual <- cor(c(N_t, NA),
                        pbs_N_fore,
                        use = "pairwise.complete.obs")

plot(N_t,
     pbs_N_fore[-101],
     xlab = "Observation of Nt",
     ylab = "Estimate of Nt having worked in log space")
abline(0, 1, col="grey")
pbs_rho_N_manual
```

Wow, so 7% correlation. Not good. So stick with not logging. Seems really poor -
maybe should double check that code. TODO Once `pbsEDM()` output clarified then
do that last bit again.

## Compare `pbsEDM` results with those from `rEDM`

Now to plot the earlier `pbsEDM` predictions again those from `rEDM`:
```{r pbsredm}
plot(NY_lags_example_3$rEDM.pred,
     pbs_pred,
     xlab = "rEDM predictions",
     ylab = "pbsEDM predictions")
abline(a=0,
       b=1,
       col="grey")

# Colour in red the ones more than eps away
eps = 0.00001      # How different the predictions can be

# Want to compare new pbsEDM results with saved rEDM
NY_lags_extended <- dplyr::mutate(NY_lags_example_3,
                                  pbsEDM.pred = pbs_pred)

different <- dplyr::filter(NY_lags_extended,
                           abs(rEDM.pred - pbsEDM.pred) > eps)
points(different$rEDM.pred,
       different$pbsEDM.pred,
       col = "red",
       pch = 20)

# Just time, observations Y_t, and predictions
dplyr::select(different, t, Y_t, rEDM.pred, pbsEDM.pred)
```
Those time indices represent $t^*+1$ values.

So there are three time values for which results differ between `pbsEDM` and `rEDM`.

## Explaining the issue

Vector $\bf{x}_t$ is the vector of lagged values of the
scalars $Y_t$:
$$\bf{x}_t = [Y_t, ~Y_{t-1}].$$
For focal time $t^*$, we know $\bf{x}_{t^*}$ and are trying to predict
$\bf{x}_{t^*+1}$. The issue is that `rEDM` seems to use $\bf{x}_{t^*+2}$ as a
nearest neighbour, but this should not be permissible.

For example, for $t^*=94$, Andy's R code calculates nearest neighbours with indices $\psi$
(saved as `psivec94`) and corresponding weights `weights94`:
```{r psi}
psivec94 = c(6, 57, 88)
weights94 = c(0.3678794, 0.3205861, 0.2895013)
```
giving the estimate of $Y_{95}$, from [S1] of Deyle et al. (2013), as
```{r Yninetyfive}
Y95est = sum(weights94 * simple_ts[psivec94+1]) / sum(weights94)
Y95est
```

The `pbsEDM` code gives the same results:
```{r}
pbs_calc$neighbour_index[94, ]
pbs_calc$neighbour_weight[94, ]
pbs_calc$X_forecast[95]
```
The following will give errors if those results don't agree:
```{r test}
testthat::expect_equal(psivec94, pbs_calc$neighbour_index[94, ])
testthat::expect_equal(weights94, pbs_calc$neighbour_weight[94, ], tolerance = 0.000001)
testthat::expect_equal(Y95est, pbs_calc$X_forecast[95])
```
However, `rEDM` gives

```{r rEDMninetyfive}
Y95est_rEDM = NY_lags_example_3$rEDM.pred[95]
Y95est_rEDM
```
as already noted above. Unlike (I think) earlier versions of `rEDM::simplex()`, the full
results (nearest neighbours etc.) do not seem returnable from `rEDM::Simplex()`
or `rEDM::simplex()` [have tried changing options `verbose, stats_only, silent`,
but none give the full results].

## Manually reproduce `rEDM` result

We can reproduce the `rEDM` result by adapting Andy's manual code to allow
$\bf{x}_{96}$ to be a nearest neighbour of $\bf{x}_{94}$,  giving
```{r psi94allow}
psivec94_allow = c(96, 6, 57)   # so 6 and 57 are now 2nd and 3rd nearest neighbours
weights94_allow = c(3.678794e-01, 1.405278e-04, 4.146457e-05)
# Note that the first weight is the same as above (by definition it's always
#  exp(-1)), but the second and third are very small because x[96] is
#  very close to x[94].
Y95est_allow = sum(weights94_allow * simple_ts[psivec94_allow+1]) /
                   sum(weights94_allow)
testthat::expect_equal(Y95est_allow,
                       Y95est_rEDM)
Y95est_allow

```
which agrees with the `Y95est_rEDM` value shown above

However, the problem is that we should not be allowed to use $\bf{x}_{96}$. For
our focal time $t^* = 94$ we are trying to predict $Y_{t^*+1} = Y_{95}$. But, by
definition, $Y_{95}$ is included in $\bf{x}_{96}$ since
$$\bf{x}_{96} = [Y_{96}, Y_{95}].$$

So $\bf{x}_{96}$ should not be used to forecast $\bf{x}_{95}$, because it
explicitly contains one of the two components of $\bf{x}_{95}$ (namely the
$Y_{95}$ value that we are trying to predict). See our manuscript for full details.

The same issue occurs for $t^*=75$.

So the implementation of `rEDM` is not taking into account the fact that
$\bf{x}_t$ is a vector of lagged values.

## Similarly, tweak the data and use `rEDM`

Try changing the value of $Y_{95}$ so that `rEDM::Simplex()` does not pick
$\bf{x}_{96}$ as a nearest neighbour for $\bf{x}_{94}$, and see if get the same result as
for `pbsEDM`.

```{r changedata}
input_obs <- dplyr::select(NY_lags_example_3, t, Y_t) %>%
  dplyr::rename(Time = t)
input_obs[95,]
input_obs_change <- input_obs
input_obs_change[95,"Y_t"] = 7    # Move it out of the way

rEDM_change <- rEDM::Simplex(dataFrame = input_obs_change,
                                   columns = "Y_t",
                                   target = "Y_t",
                                   lib = "1 99",
                                   pred = "1 99",
                                   E = 2,
                                   verbose = TRUE)$Predictions
rEDM_change <- c(NA,
                 rEDM_change)   # Needs extra NA to get indexing correct
testthat::expect_equal(pbs_pred[95],
                       rEDM_change[95])

pbs_pred[95]
rEDM_change[95]

```
Those are the same, so showing that changing $Y_{95}$ gives the
expected answer from using `rEDM::Simplex()`.

## Try alternative `exclusionRadius` settings for `rEDM`

Try changing `exclusionRadius` input in `rEDM::Simplex`, which "excludes vectors
from the search space of nearest neighbors if their relative time
index is within  exclusionRadius." as suggested in `rEDM` Issue 24.

Commenting out `expect_equal()` in these, because it creates error -- writing the
results manually as comments.

First try setting `exclusionRadius = 1` (`check_rEDM_excl_1` result is saved in
`pbsEDM` using `data-raw/exclusion_radius_test.R` and not run here):
```{r exclusion1, eval=FALSE}
check_rEDM_excl_1 <- rEDM::Simplex(dataFrame = input_obs,
                                   columns = "Y_t",
                                   target = "Y_t",
                                   lib = "1 99",
                                   pred = "1 99",
                                   E = 2,
                                   verbose = TRUE,
                                   exclusionRadius = 1)$Predictions
check_rEDM_excl_1 <- c(NA,
                       check_rEDM_excl_1)   # Needs extra NA to get indexing correct

testthat::expect_equal(NY_lags_example_3$rEDM.pred,
                       check_rEDM_excl_1)
# Fails:
# 2/100 mismatches (average diff: 0.969)
# [76]  1.368 - 0.838 ==  0.53
# [77] -0.381 - 1.027 == -1.41
# So two differences using Simplex() with exclusionRadius=0 (default) and 1.

testthat::expect_equal(pbs_pred,
                       check_rEDM_excl_1)
# Fails:
# 6/100 mismatches (average diff: 0.274)
# [19]  1.0614 - 1.0614 ==  5.82e-06 #small
# [23]  1.4783 - 1.4783 ==  8.08e-06 #small
# [77] -0.3812 - 1.0266 == -1.41e+00
# [90]  2.1994 - 2.1994 ==  1.43e-05 #small
# [95]  0.4123 - 0.1774 ==  2.35e-01
# [98]  0.0799 - 0.0799 ==  3.28e-06 #small
# So [76] now matches pbs_pred, [77] for some reason has changed, [90] is
# probably close enough, but [95] still not the same as pbs_pred.
```

Then try setting it to 2, again not run here but saved in `pbsEDM`:
```{r exclusion2, eval=FALSE}
check_rEDM_excl_2 <- rEDM::Simplex(dataFrame = input_obs,
                                   columns = "Y_t",
                                   target = "Y_t",
                                   lib = "1 99",
                                   pred = "1 99",
                                   E = 2,
                                   verbose = TRUE,
                                   exclusionRadius = 2)$Predictions
check_rEDM_excl_2 <- c(NA,
                       check_rEDM_excl_2)   # Needs extra NA to get indexing correct

# testthat::expect_equal(NY_lags_example_3$rEDM.pred,
#                        check_rEDM_excl_2)
# 4/100 mismatches (average diff: 0.931)
# [76]  1.368 - 0.838 ==  0.530  # same as exclR=1
# [77] -0.381 - 1.027 == -1.408  # same as exclR=1
# [95]  0.177 - 0.412 == -0.235
# [97] -0.798 - 0.755 == -1.552
# So this has two new differences from exclR=0

# testthat::expect_equal(pbs_pred,
#                       check_rEDM_excl_2)
# [19]  1.0614 - 1.0614 ==  5.82e-06 # small
# [23]  1.4783 - 1.4783 ==  8.08e-06 # small
# [77] -0.3812 - 1.0266 == -1.41e+00
# [90]  2.1994 - 2.1994 ==  1.43e-05 # small
# [97] -0.7977 - 0.7547 == -1.55e+00
# [98]  0.0799 - 0.0799 ==  3.28e-06 # small
```
So with exclusion radius of 2, assuming the e-06 and e-05 values are equal, instead of
$t^*+1 = 76, 90$ and 95 results disagreeing between `pbsEDM` and `rEDM` results, we now
have those three agreeing, but 77 and 97 being quite different:
```{r newdiff}
# [77] -0.3812 - 1.0266 == -1.41e+00
# [97] -0.7977 - 0.7547 == -1.55e+00
```

Try exclusion radius of 3 (also saved in `pbsEDM`):
```{r exclusion3, eval=FALSE}
check_rEDM_excl_3 <- rEDM::Simplex(dataFrame = input_obs,
                                   columns = "Y_t",
                                   target = "Y_t",
                                   lib = "1 99",
                                   pred = "1 99",
                                   E = 2,
                                   verbose = TRUE,
                                   exclusionRadius = 3)$Predictions
check_rEDM_excl_3 <- c(NA,
                       check_rEDM_excl_3)   # Needs extra NA to get indexing correct

# testthat::expect_equal(NY_lags_example_3$rEDM.pred,
#                       check_rEDM_excl_3)
# 7/100 mismatches (average diff: 0.64)
# [61]  0.797 - 0.891 == -0.0943
# [64]  0.171 - 0.150 ==  0.0209
# [65]  2.883 - 3.521 == -0.6378
# [76]  1.368 - 0.838 ==  0.5299
# [77] -0.381 - 1.027 == -1.4078
# [95]  0.177 - 0.412 == -0.2350
# [97] -0.798 - 0.755 == -1.5523
# So first three values are different (but weren't for exclR = 2), last four
# have the same differences as for exclR = 2
# (expect to get more differences with larger radius).

# testthat::expect_equal(pbs_pred,
#                       check_rEDM_excl_3)
# 9/100 mismatches (average diff: 0.413)
# [19]  1.0614 - 1.0614 ==  5.82e-06
# [23]  1.4783 - 1.4783 ==  8.08e-06
# [61]  0.7967 - 0.8910 == -9.43e-02 # new
# [64]  0.1709 - 0.1500 ==  2.09e-02 # new
# [65]  2.8828 - 3.5206 == -6.38e-01 # new
# [77] -0.3812 - 1.0266 == -1.41e+00
# [90]  2.1994 - 2.1994 ==  1.43e-05
# [97] -0.7977 - 0.7547 == -1.55e+00
# [98]  0.0799 - 0.0799 ==  3.28e-06
```
The three highlighted ones are new differences for `exclusionRadius=3`,
which, as expected, does not fix the problem.

So, conclusion is that setting `exclusionRadius` in `rEDM` does not fix the problem.

## That's all for predictions of $Y$, what about $N$?

So `pbs_pred` is a vector of predictions of the $Y_t$ values.
But we are really interested in the $N_t$ values. So get those by
un-first-differencing:

$\hat{N}_{t+1} = N_{t} + \hat{Y}_{t}$,

and in particular for the projected value

$\hat{N}_{101} = N_{100} + \hat{Y}_{100}$.

Note that we are using the known values of $N_t$ rather than estimated. Then
calculate a correlation coefficient, $\rho_N$, based on $N$ rather than $Y$
(which is what we really care about).

```{r predN}
pbs_pred_N <- c(NA,
                NY_lags_example_3$N_t + pbs_pred)

# Luke has done this already:
pbs_calc[["N_forecast"]]
# But disagrees with mine. He used:
# N_forecast <- pbsLag(N_observed) + pbsLag(c(Z_forecast, NA_real_))


```
