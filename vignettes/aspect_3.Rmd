---
title: "Aspect 3 demonstration"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{aspect_3}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  fig.width = 5,
  fig.height = 5
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

```{r setup}
library(pbsEDM)
```

## Introduction

In the manuscript, Aspect 3 is that predicted values of lagged variables can
give unrealistic negative predictions of the original unlagged populations.

Taken some from `aspect_2.Rmd` and `inclusion_issue_5.Rmd`.

Again use the simulated population time series from the manuscript, with
first-differenced values denoted $Y_t$ at $t = 1, 2, 3, ..., 99, 100$. We
extract them from the saved tibble `NY_lags_example_3`:

```{r, t_and_Y}
input <-  dplyr::select(NY_lags_example_3, t, N_t, Y_t) %>%
  dplyr::rename(Time = t)
input
```

## Calculations using pbsEDM (as done in Aspect 2 vignette)

See the [`analyse_simple_time_series`](analyse_simple_time_series.html) vignette
for general details on using the code. Here do the simplex calculation for $E = 2$:
```{r pbsEDM}
pbsEDM_res_full <- pbsEDM::pbsEDM(input,
                                  lags = list(Y_t = c(0:1)))   # Gives full calculations

pbsEDM_pred_Y <- pbsEDM_res_full$X_forecast[-length(pbsEDM_res_full$X_forecast)]
                                           # Just the predictions, excluding
                                           #  t=101, so for t = 1:100
```

## Explaining the issue -- Aspect 3

First stick with $Y_t$ calculations, convert to $N_t$. Then (at some point) try
the $N_t$ calcs directly from inclusion 5 vignette, but they gave one incorrect
calculations which was confusing (issue 29 I think).

So use:

$\hat{N}_{t+1} = N_t + \hat{Y}_t$

or

$\hat{N}_{t} = N_{t-1} + \hat{Y}_{t-1}$

```{r Npred}
pbsEDM_pred_N = c(NA,
                  input$N_t + pbsEDM_pred_Y)
pbsEDM_pred_N
```

The first three `NA`s demonstrate that we cannot predict $\hat{N}_1$ (because we do not know $N_0$), or
$\hat{N}_2$ and $\hat{N}_3$ (because we cannot predict $\hat{Y}_1$ or
$\hat{Y}_2$). Of note are the several negative predictions of $\hat{N}_t$, which
are unrealistic because our data represent populations. The indices of these
give the predicted time values (i.e. $t^* + 1$):
```{r indices}
which(pbsEDM_pred_N < 0)
```

Of particular interest is the negative prediction for $\hat{N}_{101}$, which is
likely the focus of an analysis (i.e. predict next year's population from all
currently available data).

### Differences in correlation coefficient

The Pearson correlation coefficient, $\rho$, based on the estimated $\hat{Y}_t$
and data $Y_t$ is
```{r rhoY}
pbsEDM_rho_Y <- pbsEDM_res_full$results$X_rho
pbsEDM_rho_Y
```

But comparing the estimated $\hat{N}_t$ and original $N_t$ values gives:
```{r rhoN}
pbsEDM_rho_N <- cor(c(input$N_t, NA),
                    pbsEDM_pred_N,
                    use = "pairwise.complete.obs")
pbsEDM_rho_N
```

Get 0.28, but check carefully about the NA removal, just compare the values from
$t=4:100$

```{r checking}
pbsEDM_rho_N_check <- cor(input$N_t[4:100],
                          pbsEDM_pred_N[4:100])
pbsEDM_rho_N_check
```
Gives the same answer, so is calculating properly.

Obviously those negative predictions are going to have an impact, and we know
that they are wrong. Could try the simplest choice of replacing them with the
minimum observed $N_t$:

```{r replace}
length(which(pbsEDM_pred_N < 0))   # number of negative values

N_t_min <- min(input$N_t)

pbsEDM_pred_N_replace <- pbsEDM_pred_N
pbsEDM_pred_N_replace[pbsEDM_pred_N_replace < 0] = N_t_min

pbsEDM_rho_N_replace <- cor(c(input$N_t, NA),
                            pbsEDM_pred_N_replace,
                            use = "pairwise.complete.obs")
pbsEDM_rho_N_replace    # cor(input$N_t[4:100], pbsEDM_pred_N_replace[4:100]) gives same

```

Surpisingly, that comes out worse (lower $\rho$). Don't see how that can be as we've surely moved the
predictions closer to the true values. Investigate:

THESE ARE WRONG because include all time steps, but we want to globally exclude
any with NA's.
```{r rhocalcs}
sd_pred_N <- sd(pbsEDM_pred_N, na.rm=TRUE)
sd_pred_N
sd_pred_N_replace <- sd(pbsEDM_pred_N_replace, na.rm=TRUE)
sd_pred_N_replace
```
So the vector with negatives replaced has a lower standard deviation, as
expected (since the values are now less spread out). What about the means:
```{r means}
mean_pred_N <- mean(pbsEDM_pred_N, na.rm=TRUE)
mean_pred_N
mean_pred_N_replace <- mean(pbsEDM_pred_N_replace, na.rm=TRUE)
mean_pred_N_replace
```
So replacing the negatives increases the mean, which makes sense as shifting 11
values up. A figure will help:
```{r replacefig}
plot(c(input$N_t, NA),
     pbsEDM_pred_N,
     xlab = "Observed N",
     ylab = "Predicted N",
     main = "Red: change -ve predictions to min +ve observation")

points(c(input$N_t, NA),
       pbsEDM_pred_N_replace,
       pch = 20,
       col = "red")
abline(h = mean_pred_N)
abline(h = mean_pred_N_replace,
       col = "red")
abline(v = mean(input$N_t),
       col = "grey")

lm_fit  <- lm(pbsEDM_pred_N ~ c(input$N_t, NA))
abline(lm_fit)
lm_fit_replace  <- lm(pbsEDM_pred_N_replace ~ c(input$N_t, NA))
abline(lm_fit_replace, col = "red")
```

General formula for $\rho$ is
$$\rho = \dfrac{\mbox{E}[(X - \mu_X)(Y - \mu_Y)]}{\sigma_X \sigma_Y}$$
so let $X$ here be the observed and $Y$ be the predicted.

HERE: CAN DELETE THIS CHUNK I THINK, as repeated below with no_NA, and this has
some errors in it.

```{r values}
vals <- dplyr::tibble(data = c(input$N_t, NA),
               pbsEDM_pred_N,
               pbsEDM_pred_N_replace) %>%
  dplyr::mutate(X_minus_mu_X = data - mean(data, na.rm = TRUE),
                Y_minus_mu_Y = pbsEDM_pred_N - mean_pred_N,
                Y_minus_mu_Y_replace = pbsEDM_pred_N_replace -
                  mean_pred_N_replace,
                Y_calc_diff = Y_minus_mu_Y - Y_minus_mu_Y_replace,
                numerator = X_minus_mu_X * Y_minus_mu_Y,
                numerator_replace = X_minus_mu_X * Y_minus_mu_Y_replace,
                numerator_diff = numerator - numerator_replace)
dplyr::select(vals,
              numerator,
              numerator_replace,
              numerator_diff) %>%
  as.data.frame()
sum(vals$numerator_diff, na.rm = TRUE)
num <- mean(vals$numerator, na.rm = TRUE)
num
num_replace <- mean(vals$numerator_replace, na.rm = TRUE)
num_replace
# Compare replace with original
num_replace/num
# So replacing has reduced numerator
sd_pred_N_replace / sd_pred_N
# But has reduced numerator slightly more, such that
manual_rho_increase <- (num_replace/num) / ( sd_pred_N_replace / sd_pred_N)
manual_rho_increase
rho_increase <- pbsEDM_rho_N_replace / pbsEDM_rho_N
rho_increase
```
Hmm.... so I manually calc that $\rho$ should indeed increase, in contrast to
my original calculation. Just work out $\rho$ manually:

```{r rhomanual}
sd_data <- sd(c(input$N_t, NA), na.rm = TRUE)
rho_manual <- num / sd_pred_N / sd_data
rho_manual
pbsEDM_rho_N     # Those two should be the same
rho_manual_replace <- num_replace / sd_pred_N_replace / sd_data
rho_manual_replace
pbsEDM_rho_N_replace
```

Aha -- in my manual calculations $\rho$ has increased when replacing the values.

Suggests an error in my original calculations (which may also explain why the
manual ones don't match the original ones).

## Figure out the error

Aha
```{r aha}
which(is.na(vals$X_minus_mu_X))
# But for Y we have
which(is.na(vals$Y_minus_mu_Y))
```
but we need to only use the complete ones in the manual calculations (assume
this was taken care of in `cor()`, but maybe not correctly.

Repeat the above calcs, but just reduce the tibble to exclude anything with
NA's.  TODO DELETE THE ABOVE ONE I THINK
```{r noNA}
vals_no_NA <- dplyr::tibble(data = c(input$N_t, NA),
               pbsEDM_pred_N,
               pbsEDM_pred_N_replace)
vals_no_NA <- vals_no_NA[-unique(which(is.na(vals_no_NA),
                                       arr.ind=TRUE)[, "row"]),
                         ] %>%     # Keep col names the same:
  dplyr::mutate(X_minus_mu_X = data - mean(data),
                Y_minus_mu_Y = pbsEDM_pred_N - mean(pbsEDM_pred_N),
                Y_minus_mu_Y_replace = pbsEDM_pred_N_replace -
                  mean(pbsEDM_pred_N_replace),
                Y_calc_diff = Y_minus_mu_Y - Y_minus_mu_Y_replace,
                numerator = X_minus_mu_X * Y_minus_mu_Y,
                numerator_replace = X_minus_mu_X * Y_minus_mu_Y_replace,
                numerator_diff = numerator - numerator_replace)
dplyr::select(vals_no_NA,
              numerator,
              numerator_replace,
              numerator_diff) %>%
  as.data.frame()
sum(vals_no_NA$numerator_diff)
num_no_NA <- mean(vals_no_NA$numerator)
num_no_NA
num_no_NA_replace <- mean(vals_no_NA$numerator_replace)
num_no_NA_replace
# Compare replace with original
num_no_NA_replace/num_no_NA
# So replacing has reduced numerator

sd_pred_no_NA <- sd(vals_no_NA$pbsEDM_pred_N)
sd_pred_no_NA
sd_pred_no_NA_replace <- sd(vals_no_NA$pbsEDM_pred_N_replace)
sd_pred_no_NA_replace
# So standard deviation has gone down with replacement, as found earlier, but
#  the values are different to earlier:
sd_pred_N
sd_pred_N_replace

# Aha - sd_pred_N included the t=101 value because it wasn't NA. So my
#  manual calculations above are wrong because they're not omitting the rows
#  with NA's, just the NA values.
# This should match sd_pred_no_NA:
sd(pbsEDM_pred_N[-101], na.rm=TRUE)   # It does
# And this should match sd_pred_no_NA_replace:
sd(pbsEDM_pred_N_replace[-101], na.rm=TRUE)   # it does.
```

So this should give the correct answer
```{r rhonoNA}
rho_no_NA <- cor(vals_no_NA$data,
                 vals_no_NA$pbsEDM_pred_N)
rho_no_NA
rho_no_NA_replace <- cor(vals_no_NA$data,
                         vals_no_NA$pbsEDM_pred_N_replace)
rho_no_NA_replace
```
These match my original calculations - my original manual ones were wrong.

## Do the manual calcs on 'vals no NA'

From sample example on Wikipedia
```{r manualnoNA}
rho_manual_no_NA <- sum(vals_no_NA$numerator) /
  (sqrt( sum( (vals_no_NA$X_minus_mu_X)^2 ) ) *
   sqrt( sum( (vals_no_NA$Y_minus_mu_Y)^2 ) ))
rho_manual_no_NA
pbsEDM_rho_N    # aha - matches

rho_manual_no_NA_replace <- sum(vals_no_NA$numerator_replace) /
  (sqrt( sum( (vals_no_NA$X_minus_mu_X)^2 ) ) *
   sqrt( sum( (vals_no_NA$Y_minus_mu_Y_replace)^2 ) ))
rho_manual_no_NA_replace
pbsEDM_rho_N_replace    # MATCHES
# BUT vals_no_NA has mean already in it ******* - now have fixed that above

```

HERE: so think my manual calcs now agree, so look at the details to understand
why $\rho$ decreases. Or not overly worry, as it is small and could be just one
influential point. Could sort them, if useful.

## I wonder if it's how the NA's are used.

Yes, it was. I hadn't dealt with them properly.

## Maybe mention at end

think this helps show why rho isn't great to use. So sd of Nhat goes down (as
expected) when replacing negative ones, but presumably not enough to compensate
the change in the numerator

## Test that rEDM and pbsEDM results have not changed - DO SOMETHING SIMILAR

<!--
TODO

Here we run some tests to check that if any of the above results from `pbsEDM`
or `rEDM` have changed from when this vignette was written (some results are
saved in `NY_lags_example_3`). The tests will give errors if they fail (and any
such failures should be investigated and this vignette updated).

Check the default `rEDM` predictions have not changed.
{r testrEDM}
testthat::expect_equal(NY_lags_example_3$rEDM.pred,
                       rEDM_res$Predictions)       # If no error then they match


Also check that the results with different values of `exclusionsRadius` have not changed:
{r testExcl}
testthat::expect_equal(check_rEDM_excl_1, rEDM_pred_excl_1)
testthat::expect_equal(check_rEDM_excl_2, rEDM_pred_excl_2)
testthat::expect_equal(check_rEDM_excl_3, rEDM_pred_excl_3)


The test in the Independent Code section has already verified that the `pbsEDM`
results have not changed (since they match the `my.pred` results from the original
independent code).
-->
