---
title: "Demonstration of Aspects 3 and 4"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{aspect_3_4}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  fig.width = 5,
  fig.height = 5
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

```{r setup}
library(pbsEDM)
```

## Introduction

In the manuscript, Aspect 3 is that predicted values of lagged variables can
give unrealistic negative predictions of the original unlagged populations.

Taken some from `aspect_2.Rmd` and `inclusion_issue_5.Rmd`.

Again use the simulated population time series from the manuscript, with
population size denoted $N_t$ and first-differenced values denoted $Y_t$ at $t = 1, 2, 3, ..., 99, 100$. We
extract them from the saved tibble `NY_lags_example_3`:

```{r, t_and_Y}
input <-  dplyr::select(NY_lags_example_3, t, N_t, Y_t) %>%
  dplyr::rename(Time = t)
input
```

## Calculations using pbsEDM (as done in Aspect 2 vignette)

See the [`analyse_simple_time_series`](analyse_simple_time_series.html) vignette
for general details on using the code. Here do the simplex calculation for $E = 2$:
```{r pbsEDM}
pbsEDM_res_full <- pbsEDM::pbsEDM(input,
                                  lags = list(Y_t = c(0:1)))   # Gives full calculations

pbsEDM_pred_Y <- pbsEDM_res_full$X_forecast[-length(pbsEDM_res_full$X_forecast)]
                                           # Just the predictions, excluding
                                           #  t=101, so for t = 1:100
```

## Explaining the issue -- Aspect 3

Use the $Y_t$ calculations and then convert to $N_t$. Equation (1) in the
manuscript defines $Y_t$ as:

$Y_t = N_{t+1} - N_t$.

So having estimated $\hat{Y}_t$ we can rearrange that to estimate $\hat{N}_{t+1}$ as:

$\hat{N}_{t+1} = N_t + \hat{Y}_t$

or

$\hat{N}_t = N_{t-1} + \hat{Y}_{t-1}$,

to give a vector of estimated $\hat{N}_t$ values:
```{r Npred}
pbsEDM_pred_N = c(NA,
                  input$N_t + pbsEDM_pred_Y)
pbsEDM_pred_N
```

The first three `NA` values demonstrate that we cannot predict $\hat{N}_1$ (because we do not know $N_0$), or
$\hat{N}_2$ and $\hat{N}_3$ (because we cannot predict $\hat{Y}_1$ or
$\hat{Y}_2$).

Of note are the several negative predictions of $\hat{N}_t$, which
are unrealistic because our data represent populations -- this is Aspect 3. The indices of these
give the predicted time values (i.e. $t^* + 1$):
```{r indices}
which(pbsEDM_pred_N < 0)
```

Of particular interest is the negative prediction for $\hat{N}_{101}$ of
`r  pbsEDM_pred_N[101]`, since the
aim of the analysis is often to predict next year's population from all
currently available data.

## Simple solution to Aspect 3

The simplest solution to Aspect 3 is to just replace the negative
predictions $\hat{N}_t$ with the minimum observed value of $N_t$.
```{r replace}
N_t_min <- min(input$N_t)

pbsEDM_pred_N_replace <- pbsEDM_pred_N
pbsEDM_pred_N_replace[pbsEDM_pred_N_replace < 0] = N_t_min
```

Graphically this is shown by plotting all the original $(N_t, \hat{N}_t)$ points
as open black circles, then the set with the negative $\hat{N}_t$ values
replaced as red filled circles (so that 11 points can be seen to change; the 1:1
line is added in black):

```{r replacefig, echo=FALSE}
plot(c(input$N_t, NA),
     pbsEDM_pred_N,
     xlab = "Observed N_t",
     ylab = "Predicted N_t",
     main = "Red: change -ve predictions to min +ve observation")

points(c(input$N_t, NA),
       pbsEDM_pred_N_replace,
       pch = 20,
       col = "red")
abline(a = 0, b = 1)
# abline(h = mean_pred_N)
# abline(h = mean_pred_N_replace,
#        col = "red")
# abline(v = mean(input$N_t),
#        col = "grey")

# lm_fit  <- lm(pbsEDM_pred_N ~ c(input$N_t, NA))
# abline(lm_fit)
# lm_fit_replace  <- lm(pbsEDM_pred_N_replace ~ c(input$N_t, NA))
# abline(lm_fit_replace, col = "red")
```

## Aspect 4 - good fit for the first-differenced values ($Y_t$) does not necessarily translate to a good fit to the original population sizes ($N_t$)

The above simple fix solves Aspect 3 by removing unrealistic negative
predictions. However, the above figure raises a fundamental issue, in that the
predicted values $\hat{N}_t$ do not seem to match the original data $N_t$ too
well.

The correlation coefficient of $\hat{N}_t$ and $N_t$ before correcting the
negative values is:
```{r rhoN}
pbsEDM_rho_N <- cor(c(input$N_t, NA),
                    pbsEDM_pred_N,
                    use = "pairwise.complete.obs")
pbsEDM_rho_N
```
and after correcting the negative values it is
```{r replacerho}
pbsEDM_rho_N_replace <- cor(c(input$N_t, NA),
                            pbsEDM_pred_N_replace,
                            use = "pairwise.complete.obs")
pbsEDM_rho_N_replace    # cor(input$N_t[4:100], pbsEDM_pred_N_replace[4:100]) gives same
```

The latter $\rho$ with the negatives corrected is (unintuitively) very slightly lower
than the original value. But the more important point is that a $\rho$ of 0.28
is much lower than that based on $Y_t$ and $\hat{Y}_t$, which is
```{r rhoY}
pbsEDM_rho_Y <- pbsEDM_res_full$results$X_rho
pbsEDM_rho_Y
```

This seems to have not been documented before, and so we define it as Aspect 4.

Plotting  $\hat{Y}_t$ against $Y_t$ (these are the $E=2$ points in the
manuscript's Figure~1(f):

```{r Ycorr}
plot(input$Y_t,
     pbsEDM_pred_Y,
     xlab = "Observed Y",
     ylab = "Predicted Y")
abline(a=0, b=1)
```

shows a good correspondence, as given by the correlation coefficient of
`r pbsEDM_rho_Y`.

Thus, a good correspondence based on the first-differenced $Y_t$ values does not
necessarily lead to good correspondence in the $N_t$ values, which is what we
are interested in for practical situations. Hence our recommendation that
practitioners also check the fits of the predctions based on
non-first-differenced values ($N_t$) and not just first-differenced values
($Y_t$).

HERE: Probably need something more -- should $E$ be selected based on this? How
does $E=3$ look for this data set?

This is kind of related to $\rho$ not being great to use, but the above figure
shows that we have to be careful.

## Test that rEDM and pbsEDM results have not changed - DO SOMETHING SIMILAR

TODO maybe.

<!--
TODO

Here we run some tests to check that if any of the above results from `pbsEDM`
or `rEDM` have changed from when this vignette was written (some results are
saved in `NY_lags_example_3`). The tests will give errors if they fail (and any
such failures should be investigated and this vignette updated).

Check the default `rEDM` predictions have not changed.
{r testrEDM}
testthat::expect_equal(NY_lags_example_3$rEDM.pred,
                       rEDM_res$Predictions)       # If no error then they match


Also check that the results with different values of `exclusionsRadius` have not changed:
{r testExcl}
testthat::expect_equal(check_rEDM_excl_1, rEDM_pred_excl_1)
testthat::expect_equal(check_rEDM_excl_2, rEDM_pred_excl_2)
testthat::expect_equal(check_rEDM_excl_3, rEDM_pred_excl_3)


The test in the Independent Code section has already verified that the `pbsEDM`
results have not changed (since they match the `my.pred` results from the original
independent code).
-->
