---
title: "mve_understanding"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mve_understanding}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7.1,
  fig.height = 6,
  fig.retina = 2
)
```

```{r setup}
load_all() # library(pbsEDM)
library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
```

Adapting Luke's original `mve.Rmd` to dig into his mve functions. Was going
use the same default time series as in `analyse_simple_time_series.Rmd` but
that's univariate, so stick with his larkin one.

Hao and Sugihara (2016) define, for, say Hastings and Powell x-y-z food-chain
model:

- univariate: use only x and its lags, or y and its lags, or z and its lags; not
  sure if they do simplex, don't think so.
- multivarate: do every $E$-sized combination of x, y, z with lags (excluding
  any that have no lags of 0), and take the one with the highest $\rho$ and use
  that to make the forecast;
- multiview embedding: do every $E$-sized combination of x, y, z with lags (excluding
  any that have no lags of 0), and take the $\sqrt{m}$ views with highest $\rho$ , where $m$ is number of
  $E$-dimensional combinations, and average the forecast from each one, to give
  the forecast. Important: unlike Simplex, which uses $E + 1$ nearest
  neighbours, this takes the single neares neighbour from each view and averages
  over those. For Simplex the weighting of neighbours depends on their distance,
  which can be quite sensitive to noise (Hao and Sugihara).

Not sure how $E$ gets prescribed, though could loop over it.


```{r larkin}
larkin
```

```{r visualize}
plot(larkin$time,
     larkin$recruits,
     type = "o",
     ylim = c(0, 0.2))
```

This is different format to what we have in `salmon_sim()`, so switching to
ours.
<!-- Returns are the total returns in year $t$, $r_3, r_4$, and $r_5$ are the
recruits from year $t$ that will return later. These are $R'_t$ in our write up,
so change to $R_prime_t$. Actually, not quite. So switching to ours. TODO delete -->
<!-- me when no longer needed -->

```{r simulated}
simulated <- EDMsimulate::salmon_sim()
simulated
```

Here's what we have in `EDMsimulate::sim_and_fit` and `..._realisations()`, so adapt those
(not evaluating here):
```{r simandfit, eval = FALSE}
# sim_and_fit():
sim_and_fit <- function(salmon_sim_args = list(),
                        pbsEDM_args = list(
                          lags = list(R_switch = 0,
                                      S_t = 0:3)),
                        R_switch = "R_prime_t"){

  stopifnot(R_switch %in% c("R_t", "R_prime_t"))
  stopifnot(names(pbsEDM_args$lags)[1] == "R_switch")
  names(pbsEDM_args$lags)[1] <- R_switch

  simulated <- do.call(salmon_sim,
                       salmon_sim_args)

  simulated_use <- simulated
  simulated_use[nrow(simulated_use), R_switch] = NA    # Ensure no
                                        # knowledge of it for pbsEDM(), so it
                                        # doesn't affect the rho values (else it does)

  fit <- do.call(pbsEDM::pbsEDM,
                 c(list(N = simulated_use),
                   pbsEDM_args))

  to_return <- list(simulated = simulated,
                    fit = fit)
  # concatenated list, with simulated tibble first then list of all results from pbsEDM
  return(to_return) # for now, probably want to scale down or have option to
                    # just return basic results for when doing many simulations
}

# sim_and_fit_realisations(), part of:
    if(edm_fit){
      fit_edm <- do.call(pbsEDM::pbsEDM,
                         c(list(N = all_sims[[m]]),
                           pbsEDM_args))

      testthat::expect_equal(dplyr::pull(all_sims[[m]], R_switch),
                             fit_edm$N_observed[-(T+1)])  # Extra check

      fit_edm_full_series[m, ]  <- t(c(m,
                                       fit_edm$N_forecast))

      res_realisations[m, "R_switch_T_edm_fit"] = fit_edm$N_forecast[T] # TODO
                                        # double check what to do when pbsedm
                                        # arguments change
      res_realisations[m, "E"] = fit_edm$results$E  # Though will need specific
                                                    # lags also kept track of or specified
      res_realisations[m, "N_rho"] = fit_edm$results$N_rho
      res_realisations[m, "N_rmse"] = fit_edm$results$N_rmse
      res_realisations[m, "X_rho"] = fit_edm$results$X_rho
      res_realisations[m, "X_rmse"] = fit_edm$results$X_rmse
    }
```

First just try a simple call to `single_view_embedding`, and based on the top
function above, use
```{r lagstouse}
lags_use <- list(# R_prime_t = 0,  # not for single_view I think
                 S_t = 0:3)
```

Here's what Luke had for Larkin, then try that for mine
```{r forecastlarkin}
# Larkin
if(TRUE){
  f0 <- pbsEDM::single_view_embedding(
    data = larkin,
    response = "recruits",
    lags = list(spawners = 0:8),
    index = 60,
    buffer = 10,
    window = integer(0),
    metric = "rmse",
    beyond = FALSE
  )

  f0 %>% as.data.frame()
}
```

Now try that for one of our examples, then dig into code with `browser()` to
trace what is being done. Then change arguments.

```{r forecast}
index_val <- 60
buffer_val <- 10
sve_on_simulated <- single_view_embedding(data = simulated,
                                          response = "R_prime_t",
                                          lags = lags_use,
                                          index = index_val,   # not sure what this is
                                          buffer = buffer_val,  # number of forecasts
                                            # prior to index, not sure exatly
                                            # what that means
                                          window = integer(0),  # forecast
                                            # metric moving window width, aha -
                                            # our issue with before and after I
                                            # think maybe
                                          metric = "rmse",  # presumably the
                                            # metric to test something
                                          beyond = FALSE)
sve_on_simulated %>% as.data.frame()
summary(sve_on_simulated)
```

Looks like it's only using information up to that point in time, going by the
points column. Don't think we need that (i.e. use all the data) as we're going
to test performance on the $T+1$ point. Deconstruct the function to understand
methods:

```{r ss}
ssr <- state_space_reconstruction(data = simulated,
                                  response = "R_prime_t",
                                  lags = lags_use)
head(simulated)
head(ssr)
```
Returns centred and scaled values. Have gone through function.

```{r ssd}
distances <- state_space_distances(ssr,
                                   index = index_val, # time index of the first value
                                        # to forecast - but why would you do
                                        # this? Ignore a transient, or a library
                                        # thing? TODO
                                   buffer = buffer_val)  # number of values to forecast
                                        # before index. Not sure why, vaguely
                                        # remember a discussion about it. TODO

# From single_view_embedding() for this (changin X to ssr, X_distance to distances)
  # - Rows in X are points in the SSR
  # - Each row in X_distance corresponds to a focal point in the SSR
  # - Each column in X_distance corresponds to a potential neighbour in the SSR
  # - Elements of X_distance correspond to distances to neighbours
  # - NA elements indicate disallowed neighbours for a given focal point

as_tibble(distances)
summary(distances) # First three and last columns always NA's. Rest have at
                   # least 49.
tail(distances)

# Next:
  # Compute centred and scaled forecasts ---------------------------------------

  # - Create neighbour index matrix
  # - Create neighbour matrices
  # - Project neighbour matrices
  # - Compute ssr_forecast vector
ssr_forecasts <- state_space_forecasts(ssr,
                                       distances,
                                       beyond = FALSE)
ssr_forecasts


observed <- c(dplyr::pull(simulated,
                          "R_prime_t"),
              NA)[seq_along(ssr_forecasts)]  # Not sure what NA does, gets
                                        # ignored anyway.
observed   # vector of observations

forecast <- untransform_forecasts(observed,
                                  ssr_forecasts)   # scale back to
                                                   # non-normalised

rows <- seq_along(forecast)

# This is what single_view_embedding() returns, set is being defined here:
sve_on_simulated_manually <- tibble(set = rep(0:1,
                                              c(index_val - 1,
                                                nrow(simulated) - index_val + 2))[rows],
                                    time = seq_len(nrow(simulated) + 1L)[rows],
                                    points = c(0,
                                               as.vector(apply(distances,
                                                               1,
                                                               function (x) sum(!is.na(x)))))[rows],
                                    dim = rep(ncol(ssr),
                                              nrow(simulated) + 1L)[rows],
                                    observed = observed,
                                    forecast = forecast,
                                    forecast_metrics(observed, forecast, integer(0),
                                                     "rmse"),   # 0 gives all NA's, but
                                                       # integer(0) does not;
                                                       # strange. Not quite sure
                                                       # what these are.
                                    superset_columns(simulated, lags_use, NULL))

superset_columns(simulated, lags_use, NULL)   # so creates extra columns, all 1's
                                        # though, not sure of the point.

expect_equal(sve_on_simulated,
             sve_on_simulated_manually)
# Error: `sve_on_simulated` not equal to `sve_on_simulated_manually`.
# Names: 4 string mismatches
# Length mismatch: comparison on first 12 components
# Component "mre": Modes: numeric, logical
# Component "mre": target is numeric, current is logical
# Component "rmse": Modes: numeric, logical
# Component "rmse": target is numeric, current is logical


```



## Now deconstruct mve

Use as template when get to mve. First, Luke's Larkin call:

```{r larkinmve}
# Larkin
if(FALSE){
  f01 <- pbsEDM::mve(
    data = larkin,
    response = "recruits",
    lags = list(spawners = 0:8),
    index = 60,
    buffer = 10,
    window = integer(0),
    metric = "rmse",
    beyond = FALSE,
    weight = NULL,
    n_weight = 1,
    cores = NULL)

  f01$ranks    # 51,000 rows!
  f01$summary
  f01$hindsight
  f01$results
  f01$forecast
}
```

Now to do on our simulated values, using similar call:

```{r mvecalc}
lags_use_multi <- list(R_prime_t = 0,
                       S_t = 0:3)
mve_on_simulated <- mve(data = simulated,
                        response = "R_prime_t",
                        lags = lags_use_multi,   # when I had this as lags_use,
                        # first six non-NA forecast values were
                        # same as for lags_use_multi, but not the rest
                        index = index_val,
                        buffer = buffer_val,
                        window = integer(0),
                        metric = "rmse",
                        beyond = FALSE,
                        weight = NULL,
                        n_weight = 1,
                        cores = NULL)

mve_on_simulated
```
Deconstruct `mve()` to understand the steps.

```{r mvedeconstruct1}
lags_use
subset_lags <- create_subset_lags(lags_use)
subset_lags
```

So that gives every combination, including some without any 0-lags. That's just
univariate, so try multi:
```{r mvedeconstruct2}
subset_lags_multi <- create_subset_lags(lags_use_multi)
# Order is not intuitive, but looks to cover them all (took a while to figure
# out formatting)
subset_lags_multi
```

Now do the calcs:
```{r mvecalcs}
mve_forecasts <- lapply(
  subset_lags_multi,
  FUN = single_view_embedding,
  data = simulated,
  response = "R_prime_t",
  index = index_val,
  buffer = buffer_val,
  window = integer(0),
  metric = "rmse",
  beyond = FALSE,
  superset = lags_use_multi)

weighted <- weight_single_view_embeddings(mve_forecasts,
                                          "rmse",
                                          weight = NULL,
                                          n_weight = 1)
weighted

mve_on_simulated_manually <- structure(
  list(
    data = simulated,
    observed = c(dplyr::pull(simulated, "R_prime_t"), NA),
    forecast = c(rep(NA_real_, index_val - 1), weighted$results$forecast),
    response = "R_prime_t",
    lags = lags_use_multi,
    index = index_val,
    buffer = buffer_val,
    window = integer(0),
    metric = "rmse",
    beyond = FALSE,
    n_weight = 1,
    raw_forecasts = mve_forecasts,
    ranks = weighted$ranks,
    summary = weighted$summary,
    hindsight = weighted$hindsight,
    results = weighted$results),
  class = "mve")

expect_equal(mve_on_simulated,
             mve_on_simulated_manually)

tail(mve_on_simulated$results)
```

Next - don't think this actually gives the best forecast for the next step. Does
return the values for each view.

- Figure out the settings. Use more of the data, not sure why there's all the
  NA's (think it's to get rid of transients, but that should be at the
  simulation stage not fitting stage).
