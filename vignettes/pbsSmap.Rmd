---
title: "pbsSmap example"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{pbsSmap}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "",
  fig.width = 5,
  fig.height = 5
)
options(rmarkdown.html_vignette.check_title = FALSE)
```

```{r setup}
library(pbsEDM)
```

## Introduction

Example use of the `pbsSmap()` function for implementing the S-map algorithm,
giving the results reported in the manuscript.

Again we use the simulated population time series from the manuscript, with
population size denoted $N_t$ and first-differenced values denoted $Y_t$ at $t = 1, 2, 3, ..., 99, 100$. We
extract them from the saved tibble `NY_lags_example_3`:

```{r, t_and_Y}
input <-  dplyr::select(NY_lags_example_3, t, N_t, Y_t) %>%
  dplyr::rename(Time = t)
input
```

In the [`analyse_simple_time_series`](analyse_simple_time_series.html) vignette
we used the simplex algorithm and found the optimal embedding dimension to be $E
= 3$, so we used that here.

```{r, Efix}
E_fix <- 3
```

## Calculations using pbsEDM

Since $E = 3$ we use lags of 0, 1, and 2, and test over a range of $\theta$,
where $\theta$ represents the degree of local weighting:
```{r, pbsSmap1}
theta_vec = seq(0, 5, 0.1)
rho_vec <- smap_thetavec(input,
                         lags = list(Y_t = 0:2),
                         theta_vec = theta_vec)

plot(theta_vec,
     rho_vec,
     xlab = expression("Degree of local weighting, " * theta),
     ylab = expression("Forecast skill, " * rho),
     ylim = c(0.7, 1))
```

Thus we can see that the forecast skill (measured by the correlation coefficient
$\rho$) increases as $\theta$ increases. The value $\theta = 0$ represents the global
linear solution, with the solutions becoming more locally weighted (and hence
nonlinear) as $\theta$ increases.

The maximum value of $\rho$ is, with corresponding $\theta$:
```{r, pbsSmap2}
max(rho_vec)
theta_max <- theta_vec[which.max(rho_vec)]
theta_max
```

We then test if this is signficantly different to the linear system with $\theta
= 0$, using the surrogate test from TODO: Need Ref in manuscript
```{r, pbsSmap3}
rho_vec[1]     # rho at theta=0
p_val <- smap_surrogates(input,
                         lags = list(Y_t = 0:2),
                         theta = theta_max)
p_val
```
Since the p-value is $>0.05$, we conclude that there is not sufficient evidence
that the system is nonlinear, since the fit is not significantly better to that
from using $\theta = 0$. However, the focus of our application is in making
projections, so we use the optimal $\theta$ for that:
```{r, pbsSmap4}
Smap_optimal <- pbsSmap(input,
                        lags = list(Y_t = 0:2),
                        theta = theta_max)

Yhat_100 <- Smap_optimal$Y_forecast[100]

Nhat_101 <- Yhat_100 + input$N_t[100]
Nhat_101
```

The latter gives $\hat{N}_{101}$, the projected value of the population at time
step 101. This is different to the -0.017 calculated using just the simplex
algorithm with $E=3$ in the [`Demonstration of Aspects 3 and 4`](aspect_3.html)
vignette TODO check link after rebuilding.
So Aspect 3 (predicting a negative population) is avoided here,
but there is no guarantee of this with the S-map algorithm.

Regarding Aspect 3, we can check how many negative projected values (across the
whole time series) arise from S-map calculations:
```{r, pbsSmap5}
pbsSmap_pred_Y <- Smap_optimal$Y_forecast[-length(Smap_optimal$Y_forecast)]
                                           # Just the predictions for Y_t, excluding
                                           #  t=101, so for t = 1:100
pbsSmap_pred_N = c(NA,
                   input$N_t + pbsSmap_pred_Y)
pbsSmap_pred_N
which(pbsSmap_pred_N < 0)
```
Thus there are only three time indices for which we obtain negative predictions
of $N_t$ when using S-map, compared to six when using the simplex algorithm. This
difference may be due to the higher correlation coefficient comparing
predictions of $Y_t$ to actual values when using S-map compared to simplex.

## Calculations using rEDM

```{r, rEDM1}
# From Simplex:
#rEDM_res <- rbind(c(1, input$Y_t[1], NA, NA),
#                  rEDM_res)             # Add Time = 1 values, to give t = 1:100
#
#rEDM_pred <- rEDM_res$Predictions       # Just the predicted values


rEDM_Smap <- rEDM::PredictNonlinear(dataFrame = input,
                                    columns = "Y_t",
                                    target = "Y_t",
                                    lib = "1 99",
                                    pred = "1 99",
                                    theta = theta_vec,
                                    E = 3,
                                    verbose = TRUE)
plot(theta_vec,
     rho_vec,
     xlab = expression("Degree of local weighting, " * theta),
     ylab = expression("Forecast skill, " * rho),
     ylim = c(0.7, 1))
lines(theta_vec,
      rEDM_Smap$rho,
      col = "red")
rEDM_Smap
```
The red line gives the `rEDM` results, which are close, but not exactly the
same, as those from `pbsEDM` (black circles) derived earlier.

So we now investigate whether Aspect 2 is occurring again in the `rEDM` calculations.

So use `rEDM::SMap()` for the previously calculated `theta_max`, as it gives
more detailed output:
```{r, rEDM2}
rEDM_Smap_full <- rEDM::SMap(dataFrame = input,
                             columns = "Y_t",
                             target = "Y_t",
                             lib = "1 99",
                             pred = "1 99",
                             theta = theta_max,
                             E = 3,
                             verbose = TRUE)
rEDM_Smap_pred_Y <- c(NA,
                      NA,
                      rEDM_Smap_full$predictions$Predictions)

plot(rEDM_Smap_pred_Y,
     pbsSmap_pred_Y,
     xlab = expression("rEDM predictions of " * Y_t),
     ylab = expression("pbsSmap predictions of " * Y_t))
abline(0, 1)
```

So the predicted values from the two sets of code are certainly similar, but not
exactly the same.

Work out which ones appear most different:
```{r, rEDM3}
epsilon <- 0.14
different <- dplyr::tibble(t = input$Time,
                           rEDM_Smap_pred_Y,
                           pbsSmap_pred_Y) %>%
  dplyr::mutate(diff = rEDM_Smap_pred_Y - pbsSmap_pred_Y)

different_few <- dplyr::filter(different,
                               abs(diff) > epsilon)

different_few

plot(rEDM_Smap_pred_Y,
     pbsSmap_pred_Y,
     xlab = expression("rEDM predictions of " * Y_t),
     ylab = expression("pbsSmap predictions of " * Y_t))
abline(0, 1)

points(different_few$rEDM_Smap_pred_Y,
       different_few$pbsSmap_pred_Y,
       col = "red",
       pch = 20)
```

So the largest difference occurs for $Y_{31}$, for which $t^* = 30$.

NEXT: Actually, look at full details for that one (from pbsEDM output), and see
if Aspect 2 applies, because the $t^*+1$ value has an influence. But it has
correctly excluded indices from the library of candidate neighbours:

```{r, pbsEDM6}
t_star <- 30
Smap_optimal$neighbour_index[t_star, ]
sort(Smap_optimal$neighbour_index[t_star, ])
```
Note that this matches equation (7) and (therefore) Figure 4 in the
manuscript. Such detailed output is not available from `rEDM`, so I think we
need a detailed 3-d figure, and if Aspect 2 applies we should be able to colour
those points that are incorrectly included by `rEDM` but excluded by `pbsEDM`.

We can use the `plot_phase_3d()` function, which requires an input of class
`pbsEDM`, so make that first:
```{r, pbsEDM7}
aa <- pbsEDM(NY_lags_example,
             lags = list(Y_t = 0:2))

plot_phase_3d(aa, tstar = 61, early.col.lines = NA) # looks like excluded are
   # very close
plot_phase_3d(aa, tstar = 15, early.col.lines = NA) # looks like excluded are
                                        # far away, therefore may affect mean
plot_phase_3d(aa, tstar = 30, early.col.lines = NA) # looks like excluded are
                                        # maybe influential on the mean
plot_phase_3d(aa, tstar = 94, early.col.lines = NA) # looks like fairly close

```

Interplay between being close and being far. Could just add the excluded ones as
bonus data away from the tstar value (not at the end) in `pbsEDM` so they get
included, and work out if the prediction from `rEDM` gives the same answer.



TODO: Move to Aspect 2: actually irrelevant here as we're doing $E=3$. So look
at numbers, maybe plot 3-d plot.

Aside: looking at Aspect 2 and Fig S.3 (no - that's E=3, so are results . For $t^* = 75$ we get differences for
simplex, can see that blowing up Fig S.3 and looking at the values:
```{r, vals}
input[73:76,]
```
so $(Y_{74}, Y_{75})$ and $(Y_{75}, Y_{76})$ are very close to each other, but
the latter should be excluded as a nearest neighbour of the former. This should
apply to S-map also though, so investigate....



## Check if calculations differ between pbsEDM and rEDM

## Test that pbsEDM and rEDM results have not changed - DO SOMETHING SIMILAR

TODO maybe.

<!--
TODO

Here we run some tests to check that if any of the above results from `pbsEDM`
or `rEDM` have changed from when this vignette was written (some results are
saved in `NY_lags_example_3`). The tests will give errors if they fail (and any
such failures should be investigated and this vignette updated).

Check the default `rEDM` predictions have not changed.
{r testrEDM}
testthat::expect_equal(NY_lags_example_3$rEDM.pred,
                       rEDM_res$Predictions)       # If no error then they match


Also check that the results with different values of `exclusionsRadius` have not changed:
{r testExcl}
testthat::expect_equal(check_rEDM_excl_1, rEDM_pred_excl_1)
testthat::expect_equal(check_rEDM_excl_2, rEDM_pred_excl_2)
testthat::expect_equal(check_rEDM_excl_3, rEDM_pred_excl_3)


The test in the Independent Code section has already verified that the `pbsEDM`
results have not changed (since they match the `my.pred` results from the original
independent code).
-->
